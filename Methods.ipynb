{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт базовых библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core import periodic_table\n",
    "import pymatgen.io.cif as cif\n",
    "import pymatgen.analysis.ewald as ewald"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Var_01.csv')\n",
    "df.sample(2)\n",
    "\n",
    "# all need is POSCAR as input for future engineernig\n",
    "df.drop(['energy_per_atom', 'formation_energy_per_atom', 'volume', 'nsites', 'unit_cell_formula', 'pretty_formula', 'is_hubbard', 'elements', \n",
    " 'nelements', 'e_above_hull', 'hubbards', 'is_compatible', 'spacegroup', 'task_ids', 'band_gap', 'density', \n",
    " 'icsd_id', 'icsd_ids',  'total_magnetization', 'material_id', 'oxide_type', 'tags', 'piezo', 'diel', 'full_formula'], axis='columns', inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>cif</th>\n",
       "      <th>elasticity</th>\n",
       "      <th>bulk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.580602</td>\n",
       "      <td># generated using pymatgen\\ndata_FeAg3\\n_symme...</td>\n",
       "      <td>{'G_Reuss': -15.0, 'G_VRH': 8.0, 'G_Voigt': 32...</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.293552</td>\n",
       "      <td># generated using pymatgen\\ndata_AlFe\\n_symmet...</td>\n",
       "      <td>{'G_Reuss': 133.0, 'G_VRH': 75.0, 'G_Voigt': 1...</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-41.981392</td>\n",
       "      <td># generated using pymatgen\\ndata_AlFe2\\n_symme...</td>\n",
       "      <td>{'G_Reuss': 60.0, 'G_VRH': 60.0, 'G_Voigt': 61...</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-64.628769</td>\n",
       "      <td># generated using pymatgen\\ndata_Al6Fe\\n_symme...</td>\n",
       "      <td>{'G_Reuss': 53.0, 'G_VRH': 56.0, 'G_Voigt': 58...</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-40.645991</td>\n",
       "      <td># generated using pymatgen\\ndata_Al3Fe\\n_symme...</td>\n",
       "      <td>{'G_Reuss': 51.0, 'G_VRH': 53.0, 'G_Voigt': 55...</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-49.071885</td>\n",
       "      <td># generated using pymatgen\\ndata_YFe5\\n_symmet...</td>\n",
       "      <td>{'G_Reuss': 67.0, 'G_VRH': 68.0, 'G_Voigt': 68...</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>-25.278117</td>\n",
       "      <td># generated using pymatgen\\ndata_Zn13Fe\\n_symm...</td>\n",
       "      <td>{'G_Reuss': 41.0, 'G_VRH': 42.0, 'G_Voigt': 43...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>-51.810017</td>\n",
       "      <td># generated using pymatgen\\ndata_ZrFe2\\n_symme...</td>\n",
       "      <td>{'G_Reuss': 71.0, 'G_VRH': 72.0, 'G_Voigt': 73...</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-51.939510</td>\n",
       "      <td># generated using pymatgen\\ndata_Zr2Fe\\n_symme...</td>\n",
       "      <td>{'G_Reuss': 30.0, 'G_VRH': 32.0, 'G_Voigt': 35...</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>-69.092475</td>\n",
       "      <td># generated using pymatgen\\ndata_Zr3Fe\\n_symme...</td>\n",
       "      <td>{'G_Reuss': 35.0, 'G_VRH': 36.0, 'G_Voigt': 37...</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        energy                                                cif  \\\n",
       "2   -15.580602  # generated using pymatgen\\ndata_FeAg3\\n_symme...   \n",
       "4   -11.293552  # generated using pymatgen\\ndata_AlFe\\n_symmet...   \n",
       "5   -41.981392  # generated using pymatgen\\ndata_AlFe2\\n_symme...   \n",
       "7   -64.628769  # generated using pymatgen\\ndata_Al6Fe\\n_symme...   \n",
       "9   -40.645991  # generated using pymatgen\\ndata_Al3Fe\\n_symme...   \n",
       "..         ...                                                ...   \n",
       "550 -49.071885  # generated using pymatgen\\ndata_YFe5\\n_symmet...   \n",
       "563 -25.278117  # generated using pymatgen\\ndata_Zn13Fe\\n_symm...   \n",
       "566 -51.810017  # generated using pymatgen\\ndata_ZrFe2\\n_symme...   \n",
       "568 -51.939510  # generated using pymatgen\\ndata_Zr2Fe\\n_symme...   \n",
       "571 -69.092475  # generated using pymatgen\\ndata_Zr3Fe\\n_symme...   \n",
       "\n",
       "                                            elasticity   bulk  \n",
       "2    {'G_Reuss': -15.0, 'G_VRH': 8.0, 'G_Voigt': 32...  133.0  \n",
       "4    {'G_Reuss': 133.0, 'G_VRH': 75.0, 'G_Voigt': 1...   85.0  \n",
       "5    {'G_Reuss': 60.0, 'G_VRH': 60.0, 'G_Voigt': 61...  117.0  \n",
       "7    {'G_Reuss': 53.0, 'G_VRH': 56.0, 'G_Voigt': 58...  106.0  \n",
       "9    {'G_Reuss': 51.0, 'G_VRH': 53.0, 'G_Voigt': 55...  125.0  \n",
       "..                                                 ...    ...  \n",
       "550  {'G_Reuss': 67.0, 'G_VRH': 68.0, 'G_Voigt': 68...  105.0  \n",
       "563  {'G_Reuss': 41.0, 'G_VRH': 42.0, 'G_Voigt': 43...   86.0  \n",
       "566  {'G_Reuss': 71.0, 'G_VRH': 72.0, 'G_Voigt': 73...  147.0  \n",
       "568  {'G_Reuss': 30.0, 'G_VRH': 32.0, 'G_Voigt': 35...  124.0  \n",
       "571  {'G_Reuss': 35.0, 'G_VRH': 36.0, 'G_Voigt': 37...  104.0  \n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract bulk moduli\n",
    "df['bulk'] = df.elasticity.apply(lambda x: eval(x)['K_VRH'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted value\n",
    "pred_val = 'bulk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elem_props(elem):\n",
    "    elem_props = {}\n",
    "    elem_props['Z'] = periodic_table.Element(elem).Z\n",
    "    elem_props['X'] = periodic_table.Element(elem).X\n",
    "    elem_props['oxidation_states'] = periodic_table.Element(elem).oxidation_states\n",
    "    elem_props['row'] = periodic_table.Element(elem).row\n",
    "    elem_props['group'] = periodic_table.Element(elem).group\n",
    "    elem_props['atomic_mass'] = periodic_table.Element(elem).atomic_mass\n",
    "    elem_props['atomic_radius'] = periodic_table.Element(elem).atomic_radius\n",
    "    elem_props['electrical_resistivity'] = periodic_table.Element(elem).electrical_resistivity\n",
    "    elem_props['velocity_of_sound'] = periodic_table.Element(elem).velocity_of_sound\n",
    "    elem_props['molar_volume'] = periodic_table.Element(elem).density_of_solid\n",
    "    elem_props['thermal_conductivity'] = periodic_table.Element(elem).thermal_conductivity\n",
    "    elem_props['melting_point'] = periodic_table.Element(elem).melting_point\n",
    "    elem_props['average_ionic_radius'] = periodic_table.Element(elem).average_ionic_radius\n",
    "    elem_props['average_cationic_radius'] = periodic_table.Element(elem).average_cationic_radius\n",
    "    elem_props['average_anionic_radius'] = periodic_table.Element(elem).average_anionic_radius\n",
    "\n",
    "    return elem_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for the futures extracting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract pymatgen structure object from cif file as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_struct(file_cif):\n",
    "    imported_cif = cif.CifParser.from_string(file_cif) #; print(imported_cif)\n",
    "    struct = imported_cif.get_structures()[0] #; print(struct)\n",
    "    return struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function on Ewald summation as the convolutional layer for crystalline graph\n",
    "\n",
    "$ E = \\sum {\\frac {F_1 \\times F_2}{|r_i-r_j|}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewald_sum(struct):\n",
    "    ew = ewald.EwaldSummation(struct, \n",
    "                         real_space_cut=None, \n",
    "                         recip_space_cut=None, \n",
    "                         eta=None, \n",
    "                         acc_factor=12.0, \n",
    "                         w=0.7071067811865475, \n",
    "                         compute_forces=False)\n",
    "    \n",
    "    return ew.total_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charged structure is mandatory for Ewald summation procedure\n",
    "\n",
    "We want to replace simple atomic oxidation states by another properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ox_dict(struct, prop):\n",
    "    ox_dict={}\n",
    "    for i in struct.species:\n",
    "        try:\n",
    "            ox_dict[str(i)] = round(get_elem_props(i)[prop])\n",
    "        except Exception as e:\n",
    "            ox_dict[str(i)] = np.nan\n",
    "            print(e)\n",
    "    return ox_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to get pymatgen.core.Structure obj. as the charged structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_charged_struct(file_cif, ox_dict):\n",
    "    imported_cif = cif.CifParser.from_string(file_cif)\n",
    "    struct = imported_cif.get_structures()[0]\n",
    "    try:\n",
    "        struct.add_oxidation_state_by_element(ox_dict)\n",
    "        return struct\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can summarize previous functions to get a result of Ewald summation from one line of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ew(file_cif, p):\n",
    "    struct = get_struct(file_cif)\n",
    "    ox_dict = get_ox_dict(struct, p) #; print(ox_dict)\n",
    "    charged_struct = get_charged_struct(file_cif, ox_dict) #; print(charged_struct)\n",
    "    try:\n",
    "        ew = ewald_sum(charged_struct) #; print(ew)\n",
    "        return (ew*-1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property: 3/8, Progress: 10/10 \r"
     ]
    }
   ],
   "source": [
    "props = ['Z', 'X', 'row', 'group', 'atomic_mass', 'atomic_radius', 'thermal_conductivity', 'melting_point'] \n",
    "\n",
    "d = df.sample(10).copy()\n",
    "\n",
    "# instantiate progress\n",
    "total = d.shape[0]\n",
    "\n",
    "p_counter = 0\n",
    "p_len = len(props) #; print(p_len)\n",
    "\n",
    "for p in props:\n",
    "    df_processed = pd.DataFrame()\n",
    "    tmp = {}\n",
    "    p_counter += 1\n",
    "    progress = 0\n",
    "    \n",
    "    # cs corresponds to single cif as string\n",
    "    for cs in d['cif']:\n",
    "        f = get_ew(cs, p)\n",
    "        tmp[p] = f\n",
    "        df_processed = df_processed.append([tmp])\n",
    "        \n",
    "        # update progress\n",
    "        progress += 1\n",
    "        print(f'Property: {p_counter}/{p_len}, Progress: {progress}/{total} ', end='\\r')\n",
    "    \n",
    "    d[p] = df_processed.values\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение функций к датасету:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEC_array = []\n",
    "# TEN_array = []\n",
    "# weights_array = []\n",
    "\n",
    "# for formula in df_init['unit_cell_formula']:\n",
    "#     dict = eval(formula)\n",
    "    \n",
    "#     try:\n",
    "#         VEC_array.append(get_VEC(dict))\n",
    "#     except:\n",
    "#         VEC_array.append(np.nan)\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         TEN_array.append(get_TEN(dict))\n",
    "#     except:\n",
    "#         TEN_array.append(np.nan)\n",
    "#         continue\n",
    "\n",
    "# df = df_init.copy()\n",
    "\n",
    "# # df['VEC'] = VEC_array\n",
    "# # df['TEN'] = TEN_array\n",
    "# df = df.drop(['energy',  'volume', 'formation_energy_per_atom', 'nsites', 'unit_cell_formula', 'pretty_formula', 'is_hubbard', 'elements', #'Unnamed: 0',\n",
    "#                    'total_magnetization', 'material_id', 'oxide_type', 'tags', 'elasticity', 'piezo', 'diel', 'full_formula', 'nelements', # 'cif_parsed',\n",
    "#                    'e_above_hull', 'hubbards', 'is_compatible', 'spacegroup', 'task_ids', 'band_gap', 'density', 'icsd_id', 'icsd_ids', 'cif'], axis='columns')\n",
    "# df = df.dropna()\n",
    "\n",
    "# if 'cif_parsed' in df.columns:\n",
    "#     df = df.drop(['cif_parsed'], axis='columns')\n",
    "    \n",
    "# if 'Unnamed: 0' in df.columns:\n",
    "#     df = df.drop(['Unnamed: 0'], axis='columns')\n",
    "    \n",
    "# print(\"Датасет содержит записей:\", df.shape[0])\n",
    "# print(\"Датасет содержит колонок:\", df.shape[1])\n",
    "# print(\"------------------------------------\", \"\\n\")\n",
    "\n",
    "# print(\"Пример записи датасета:\")\n",
    "# df.sample(1)\n",
    "# # df.reset_index().set_index(['pretty_formula']).drop(['index'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вектор признаков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Использоавание массовых соотношений по усмотрению\n",
    "* В данном примере использованы только базовые признаки, добавление признаков может существенно улучшить результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop([pred_val], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df[pred_val].values.ravel()\n",
    "# print(\"Число элементов в массиве прогнозируемой величины (\"+str(pred_val)+\"):\", str(y.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Доля данных, отнесенная к тестоваой выборке\n",
    "# test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "# print(\"Соотношение объема обучающей/тестовой выборок: \"+str(X_train.shape[0])+'/'+str(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормировка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# # Create the scaler object with a range of 0-1\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# #scaler = StandardScaler()\n",
    "\n",
    "# # Fit on the training data\n",
    "# scaler.fit(X)\n",
    "\n",
    "# # Transform both the training and testing data\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# print(\"Проверка выборок:\")\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ корреляций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Карта корреляций "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = df.corr()\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "# plt.imshow(corr_matrix, cmap='coolwarm')\n",
    "# plt.colorbar()  # add color intensity map\n",
    "\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "# plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "# plt.yticks(range(len(corr_matrix)), corr_matrix.index)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Диаграмма корреляций прогнозируемой величины с величинами из набора векторов признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_4_analysis = pd.DataFrame().append(X)\n",
    "# data_4_analysis[pred_val] = y\n",
    "\n",
    "# # bar plot\n",
    "# pd.DataFrame(data_4_analysis.corr()[pred_val]).\\\n",
    "#              drop(index=[pred_val]).\\\n",
    "#              sort_values(by=[pred_val], ascending=False).\\\n",
    "#              plot(kind='bar')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ВНИАМАНИЕ!**\n",
    "\n",
    "В примере не приводится существенная оптимизация моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регрессионные модели МО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение используемой метрики (для всех регрессионных моделей):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring='r2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Метрики регрессии:*\n",
    "- `explained_variance`\n",
    "- `max_error`\n",
    "- `neg_mean_absolute_error`\n",
    "- `neg_mean_squared_error`\n",
    "- `neg_root_mean_squared_error`\n",
    "- `neg_mean_squared_log_error`\n",
    "- `neg_median_absolute_error`\n",
    "- `r2`\n",
    "- `neg_mean_poisson_deviance`\n",
    "- `neg_mean_gamma_deviance`\n",
    "- `neg_mean_absolute_percentage_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_table = pd.DataFrame()\n",
    "# tmp={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция построения графика $y_{pred}=f(y_{true})$ и отображения метрики $R^2$ в кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ex_plot(model_name, y_true, y_pred, scores):\n",
    "#     plt.plot(y_test, y_pred, 'o', label=str(scoring)+'(C-V) = '+str(round(scores,2)))\n",
    "    \n",
    "#     max_dimension = max(y_test.max(), y_pred.max())\n",
    "#     min_dimension = min(y_test.min(), y_pred.min())\n",
    "    \n",
    "#     x_line = [min_dimension, max_dimension]\n",
    "#     y_line = x_line\n",
    "    \n",
    "#     plt.plot(x_line, y_line)\n",
    "#     plt.xlabel('True value')\n",
    "#     plt.ylabel('Predicted value')\n",
    "#     plt.legend()\n",
    "#     plt.title(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение модели линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LinearRegression()\n",
    "\n",
    "# ''' MODEL FIT '''\n",
    "# lr.fit(X_train, y_train)\n",
    "   \n",
    "# ''' Cross-Validation '''\n",
    "# scores = cross_val_score(lr, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "# ''' PLOT '''\n",
    "# y_pred = lr.predict(X_test)\n",
    "# model_name='Linear Regression'\n",
    "# # ex_plot(model_name, y_test, y_pred, scores.mean())\n",
    "# # plt.show()\n",
    "\n",
    "# tmp['model'] = 'lr'\n",
    "# tmp[scoring] = scores.mean()\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загрузка библиотек\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Инициализация модели МО:\n",
    "# model_knr = KNeighborsRegressor()\n",
    "\n",
    "# # Массив числа соседей для перебора\n",
    "# n_neighbors = np.arange(1,11,1) # from 1 to 10\n",
    "\n",
    "# # Определение сетки параметров\n",
    "# param_grid = {'n_neighbors': n_neighbors}\n",
    "\n",
    "# # Инициирование поиска по сетке параметров\n",
    "# gs = GridSearchCV(model_knr, param_grid, cv = 5, verbose = 1, n_jobs=-1, scoring=scoring)\n",
    "# gs.fit(X_train, y_train)\n",
    "\n",
    "# # Определение наилучшей параметризации\n",
    "# model_best = gs.best_estimator_\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Таблица результатов поиска по сетке параметров\n",
    "# results = pd.DataFrame()\n",
    "# results['params'] = gs.cv_results_.get('params')\n",
    "# results['scores'] = gs.cv_results_.get('mean_test_score')\n",
    "# results['rank'] = gs.cv_results_.get('rank_test_score')\n",
    "# knn_res = results.sort_values(by='rank').set_index('rank')\n",
    "\n",
    "# tmp['model'] = 'knn'\n",
    "# tmp[scoring] = knn_res.head(1).scores.values[0]\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загрузка библиотек\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# # Инициализация модели МО:\n",
    "# svr = SVR()\n",
    "\n",
    "# # Массив параметров для перебора\n",
    "# kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# degree = [1]\n",
    "# tol = [0.0001, 0.001]\n",
    "# C = [0.6]\n",
    "# epsilon = [0.2]\n",
    "\n",
    "# param_grid = {'kernel': kernel, 'degree' : degree, 'tol' : tol, 'C' : C, 'epsilon' : epsilon}\n",
    "\n",
    "# gs = GridSearchCV(svr, param_grid, cv = 5, verbose = 1, n_jobs=-1, scoring=scoring)\n",
    "# gs.fit(X_train, y_train)\n",
    "# model_best = gs.best_estimator_\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Таблица результатов поиска по сетке параметров\n",
    "# results = pd.DataFrame()\n",
    "# results['params'] = gs.cv_results_.get('params')\n",
    "# results['scores'] = gs.cv_results_.get('mean_test_score')\n",
    "# results['rank'] = gs.cv_results_.get('rank_test_score')\n",
    "# svm_res = results.sort_values(by='rank').set_index('rank')\n",
    "\n",
    "# tmp['model'] = 'svm'\n",
    "# tmp[scoring] = svm_res.head(1).scores.values[0]\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# RFR = RandomForestRegressor()\n",
    "\n",
    "# n_estimators = [400, 500]\n",
    "# max_features = ['auto']\n",
    "# max_depth = [40]\n",
    "# min_samples_split = [0.001]\n",
    "# min_samples_leaf = [1]\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# param_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# gs = GridSearchCV(RFR, param_grid, cv = 5, verbose = 1, n_jobs=-1, scoring=scoring)\n",
    "# gs.fit(X_train, y_train)\n",
    "\n",
    "# model_best = gs.best_estimator_\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Таблица результатов поиска по сетке параметров\n",
    "# results = pd.DataFrame()\n",
    "# results['params'] = gs.cv_results_.get('params')\n",
    "# results['scores'] = gs.cv_results_.get('mean_test_score')\n",
    "# results['rank'] = gs.cv_results_.get('rank_test_score')\n",
    "# rfr_res = results.sort_values(by='rank').set_index('rank')\n",
    "\n",
    "# tmp['model'] = 'rfr'\n",
    "# tmp[scoring] = rfr_res.head(1).scores.values[0]\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# gbr = GradientBoostingRegressor()\n",
    "\n",
    "# # Массивы значений параметров для поиска по сетке\n",
    "# learning_rate = [0.001, 0.01, 0.1]\n",
    "# n_estimators = [300,350]\n",
    "# min_samples_split = [0.001,0.01, 0.1]\n",
    "# min_samples_leaf = [1,2]\n",
    "# max_depth = [1,5,15]\n",
    "\n",
    "# param_grid = { 'learning_rate': learning_rate,\n",
    "#                'n_estimators': n_estimators,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'max_depth': max_depth}\n",
    "\n",
    "# gs = GridSearchCV(gbr, param_grid, cv = 5, verbose = 1, n_jobs=-1, scoring=scoring)\n",
    "# gs.fit(X_train, y_train)\n",
    "# model_best = gs.best_estimator_\n",
    "# # print(\"------------------------------\")\n",
    "# # print(\"Параметры наилучшего варианта:\")\n",
    "# # print(gs.best_params_)\n",
    "# # print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Таблица результатов поиска по сетке параметров\n",
    "# results = pd.DataFrame()\n",
    "# results['params'] = gs.cv_results_.get('params')\n",
    "# results['scores'] = gs.cv_results_.get('mean_test_score')\n",
    "# results['rank'] = gs.cv_results_.get('rank_test_score')\n",
    "# gbr_res = results.sort_values(by='rank').set_index('rank').head(3)\n",
    "\n",
    "# tmp['model'] = 'gbr'\n",
    "# tmp[scoring] = gbr_res.head(1).scores.values[0]\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(df.columns.values)\n",
    "# # res_table.r2.max()\n",
    "# res_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pre-requirements\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras import optimizers\n",
    "\n",
    "# # keras-tuner (general)\n",
    "# import tensorflow.keras as keras\n",
    "\n",
    "# # hyperparameter optimization algorithm\n",
    "# from kerastuner import Hyperband # OTHER MODULES: RandomSearch, BayesianOptimization\n",
    "\n",
    "# # easy calling\n",
    "# from kerastuner.engine.hypermodel import HyperModel\n",
    "# from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(hp):\n",
    "    \n",
    "#     ''' trial parameters '''\n",
    "#     # model type selection\n",
    "#     model = Sequential()\n",
    "        \n",
    "#     # model hyperparameters\n",
    "#     activation_choice = hp.Choice('activation', values=['relu', 'sigmoid'])\n",
    "#     optimizer_choice = hp.Choice('optimizer', values=['adam','rmsprop','SGD'])\n",
    "#     hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) \n",
    "    \n",
    "#     ''' ANN STRUCTURE '''\n",
    "#     # first h-layer\n",
    "#     model.add(Dense(units=hp.Int('layer_1', min_value=20, max_value=200, step=20),\n",
    "#                     input_dim=9,\n",
    "#                     activation=activation_choice))\n",
    "    \n",
    "#     # other h-layer \n",
    "#     # optimized for perfomance\n",
    "#     for i in range(hp.Int('num_layers', 2, 4)):\n",
    "#         model.add(Dense(units=hp.Int('layer_' + str(i), min_value=20, max_value=100, step=20),\n",
    "#                         activation=activation_choice))\n",
    "    \n",
    "#     # output layer\n",
    "#     model.add(Dense(1))\n",
    "    \n",
    "#     ''' instantiate ANN '''\n",
    "#     model.compile(optimizer=optimizer_choice,\n",
    "#                   loss='MSE',\n",
    "#                   metrics=['MSE'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = Hyperband(build_model,\n",
    "#                   objective='val_MSE',\n",
    "#                   max_epochs=500, # for Hyperband only\n",
    "#                   #max_trials=20, # for BayesianOptimization & RandomSearch\n",
    "#                   directory='test_dir') #, # ATTENTION! path should be latin!!!!!!\n",
    "#                   #overwrite=True) # overwrite all previous models in specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search(X_train, y_train, \n",
    "#              batch_size=200, # optimal batch size preselected\n",
    "#              # epochs=500,   # for BayesianOptimization & RandomSearch\n",
    "#              validation_split=0.2,\n",
    "#              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = tuner.get_best_models(num_models=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = models[0]\n",
    "# m2 = models[1]\n",
    "# m3 = models[2]\n",
    "# # m1.fit(X_train, y_train)\n",
    "# # m2.fit(X_train, y_train)\n",
    "# # m3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# def get_X_y(df_test, df_train):    \n",
    "#     X_train = df_train.copy().drop([pred_val], axis='columns')\n",
    "#     y_train = pd.DataFrame(df_train[pred_val])\n",
    "#     X_test = df_test.copy().drop([pred_val], axis='columns')\n",
    "#     y_test = pd.DataFrame(df_test[pred_val])\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     return X_train, y_train, X_test, y_test\n",
    "    \n",
    "# def get_predictions(model, X_train, y_train, X_test, y_test):\n",
    "#     model.fit(X_train, y_train, epochs=100, verbose=2)\n",
    "#     predicticted_values = model(X_test).numpy()\n",
    "#     predicticted_values = predicticted_values.reshape(predicticted_values.shape[0]) \n",
    "#     R2 = r2_score(y_test, predicticted_values) \n",
    "#     return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import IntProgress\n",
    "# from IPython.display import display\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# # splits number for k-fold C-V\n",
    "# n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "\n",
    "# # instantiate the bar\n",
    "# progress_bar = IntProgress(min=0, max=n_splits)\n",
    "# percentage = round(progress_bar.value*100/n_splits)\n",
    "# display(progress_bar) # display the bar\n",
    "\n",
    "# # temporary data for futher plotting\n",
    "# hist = pd.DataFrame()\n",
    "# tmp = {}\n",
    "\n",
    "# for train, test in kf.split(df):\n",
    "# #     new_model = m1\n",
    "#     new_model = keras.models.load_model('best_model.h5')\n",
    "#     df_train = df.iloc[train]\n",
    "#     df_test = df.iloc[test]\n",
    "#     X_train, y_train, X_test, y_test = get_X_y(df_test, df_train)\n",
    "#     R2 = get_predictions(new_model, X_train, y_train, X_test, y_test)\n",
    "#     tmp['Fold'] = progress_bar.value\n",
    "#     tmp['R2'] = R2\n",
    "#     hist = hist.append([tmp])\n",
    "    \n",
    "#     # progress bar update\n",
    "#     progress_bar.value += 1\n",
    "#     percentage = round(progress_bar.value*100/n_splits)\n",
    "#     progress_bar.description = str(percentage)+\" %\"\n",
    "\n",
    "# hist = hist.set_index(['Fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('best_model.h5')\n",
    "# model.fit(X_train, y_train, epochs=200)\n",
    "# predicticted_values = model(X_test).numpy()\n",
    "# predicticted_values = predicticted_values.reshape(predicticted_values.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(y_test, predicticted_values, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Восстановим в точности ту же модель, включая веса и оптимизатор\n",
    "# new_model = keras.models.load_model('best_model.h5')\n",
    "\n",
    "# # Покажем архитектуру модели\n",
    "# new_model.summary()\n",
    "\n",
    "# plot_model_fit(new_model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
