{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт базовых библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>energy_per_atom</th>\n",
       "      <th>volume</th>\n",
       "      <th>formation_energy_per_atom</th>\n",
       "      <th>nsites</th>\n",
       "      <th>unit_cell_formula</th>\n",
       "      <th>pretty_formula</th>\n",
       "      <th>is_hubbard</th>\n",
       "      <th>elements</th>\n",
       "      <th>nelements</th>\n",
       "      <th>...</th>\n",
       "      <th>icsd_ids</th>\n",
       "      <th>cif</th>\n",
       "      <th>total_magnetization</th>\n",
       "      <th>material_id</th>\n",
       "      <th>oxide_type</th>\n",
       "      <th>tags</th>\n",
       "      <th>elasticity</th>\n",
       "      <th>piezo</th>\n",
       "      <th>diel</th>\n",
       "      <th>full_formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-11.331285</td>\n",
       "      <td>-5.665643</td>\n",
       "      <td>98.236577</td>\n",
       "      <td>-0.181752</td>\n",
       "      <td>2</td>\n",
       "      <td>{'Fe': 1.0, 'O': 1.0}</td>\n",
       "      <td>FeO</td>\n",
       "      <td>True</td>\n",
       "      <td>['Fe', 'O']</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td># generated using pymatgen\\ndata_FeO\\n_symmetr...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>mp-1181437</td>\n",
       "      <td>oxide</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fe1O1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-72.083006</td>\n",
       "      <td>-7.208301</td>\n",
       "      <td>71.846658</td>\n",
       "      <td>-0.170929</td>\n",
       "      <td>10</td>\n",
       "      <td>{'Fe': 2.0, 'B': 8.0}</td>\n",
       "      <td>FeB4</td>\n",
       "      <td>False</td>\n",
       "      <td>['B', 'Fe']</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[196424, 425311]</td>\n",
       "      <td># generated using pymatgen\\ndata_FeB4\\n_symmet...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>mp-1079437</td>\n",
       "      <td>None</td>\n",
       "      <td>['Iron tetraboride', 'Iron boride (1/4)']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fe2B8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        energy  energy_per_atom     volume  formation_energy_per_atom  nsites  \\\n",
       "256 -11.331285        -5.665643  98.236577                  -0.181752       2   \n",
       "26  -72.083006        -7.208301  71.846658                  -0.170929      10   \n",
       "\n",
       "         unit_cell_formula pretty_formula  is_hubbard     elements  nelements  \\\n",
       "256  {'Fe': 1.0, 'O': 1.0}            FeO        True  ['Fe', 'O']          2   \n",
       "26   {'Fe': 2.0, 'B': 8.0}           FeB4       False  ['B', 'Fe']          2   \n",
       "\n",
       "     ...          icsd_ids                                                cif  \\\n",
       "256  ...                []  # generated using pymatgen\\ndata_FeO\\n_symmetr...   \n",
       "26   ...  [196424, 425311]  # generated using pymatgen\\ndata_FeB4\\n_symmet...   \n",
       "\n",
       "     total_magnetization material_id oxide_type  \\\n",
       "256             4.000000  mp-1181437      oxide   \n",
       "26              0.000045  mp-1079437       None   \n",
       "\n",
       "                                          tags  elasticity  piezo diel  \\\n",
       "256                                         []         NaN    NaN  NaN   \n",
       "26   ['Iron tetraboride', 'Iron boride (1/4)']         NaN    NaN  NaN   \n",
       "\n",
       "    full_formula  \n",
       "256        Fe1O1  \n",
       "26         Fe2B8  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Var_01.csv')\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_val = 'energy_per_atom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка дополнительных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Периодическая таблица химических эелементов\n",
    "# periodic_table = pd.read_csv('Periodic_Table.csv')\n",
    "\n",
    "# # Таблица валентностей\n",
    "# valency = pd.read_csv(filepath_or_buffer = \"Default_PAW_potentials_VASP.csv\", sep = ';')\n",
    "\n",
    "# # Таблица электроотрицательности химических элементов\n",
    "# electronegativity = pd.read_csv(\"Pauling_scale.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление данных об упругости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shear_moduli = []\n",
    "# bulk_moduli = []\n",
    "\n",
    "# for item in df_init['elasticity']:\n",
    "#     if type(item) == str:\n",
    "#         elastic_props = eval(item)\n",
    "#         shear_moduli.append(elastic_props['G_VRH'])\n",
    "#         bulk_moduli.append(elastic_props['K_VRH'])\n",
    "#     else:\n",
    "#         shear_moduli.append(np.nan)\n",
    "#         bulk_moduli.append(np.nan)\n",
    "\n",
    "# df_init['Shear'] = shear_moduli\n",
    "# df_init['Bulk'] = bulk_moduli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции расчета базовых элементов вектора признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Функция расчета концентрации валентных электронов\n",
    "# def get_VEC(unit_cell_formula):\n",
    "#     S = sum(unit_cell_formula.values())\n",
    "#     valency_sum = 0\n",
    "#     for elem in unit_cell_formula.keys():\n",
    "#         V = valency[valency['Element']  == elem].valency.values[0]\n",
    "#         N = unit_cell_formula.get(elem)\n",
    "#         valency_sum += V*N\n",
    "#     VEC = valency_sum/S\n",
    "    \n",
    "#     return VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TEN calculation function\n",
    "# def get_TEN(dict):\n",
    "#     S = sum(dict.values())\n",
    "#     ten_sum = 0\n",
    "#     for elem in dict.keys():\n",
    "#         ten = float(electronegativity[electronegativity['Symbol']  == elem].use.values)\n",
    "#         N = dict.get(elem)\n",
    "#         ten_sum += ten*N\n",
    "        \n",
    "#     TEN = ten_sum/S\n",
    "    \n",
    "#     return TEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение функций к датасету:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEC_array = []\n",
    "# TEN_array = []\n",
    "# weights_array = []\n",
    "\n",
    "# for formula in df_init['unit_cell_formula']:\n",
    "#     dict = eval(formula)\n",
    "    \n",
    "#     try:\n",
    "#         VEC_array.append(get_VEC(dict))\n",
    "#     except:\n",
    "#         VEC_array.append(np.nan)\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         TEN_array.append(get_TEN(dict))\n",
    "#     except:\n",
    "#         TEN_array.append(np.nan)\n",
    "#         continue\n",
    "\n",
    "# df = df_init.copy()\n",
    "\n",
    "# # df['VEC'] = VEC_array\n",
    "# # df['TEN'] = TEN_array\n",
    "# df = df.drop(['energy',  'volume', 'formation_energy_per_atom', 'nsites', 'unit_cell_formula', 'pretty_formula', 'is_hubbard', 'elements', #'Unnamed: 0',\n",
    "#                    'total_magnetization', 'material_id', 'oxide_type', 'tags', 'elasticity', 'piezo', 'diel', 'full_formula', 'nelements', # 'cif_parsed',\n",
    "#                    'e_above_hull', 'hubbards', 'is_compatible', 'spacegroup', 'task_ids', 'band_gap', 'density', 'icsd_id', 'icsd_ids', 'cif'], axis='columns')\n",
    "# df = df.dropna()\n",
    "\n",
    "# if 'cif_parsed' in df.columns:\n",
    "#     df = df.drop(['cif_parsed'], axis='columns')\n",
    "    \n",
    "# if 'Unnamed: 0' in df.columns:\n",
    "#     df = df.drop(['Unnamed: 0'], axis='columns')\n",
    "    \n",
    "# print(\"Датасет содержит записей:\", df.shape[0])\n",
    "# print(\"Датасет содержит колонок:\", df.shape[1])\n",
    "# print(\"------------------------------------\", \"\\n\")\n",
    "\n",
    "# print(\"Пример записи датасета:\")\n",
    "# df.sample(1)\n",
    "# # df.reset_index().set_index(['pretty_formula']).drop(['index'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вектор признаков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Использоавание массовых соотношений по усмотрению\n",
    "* В данном примере использованы только базовые признаки, добавление признаков может существенно улучшить результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop([pred_val], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df[pred_val].values.ravel()\n",
    "# print(\"Число элементов в массиве прогнозируемой величины (\"+str(pred_val)+\"):\", str(y.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Доля данных, отнесенная к тестоваой выборке\n",
    "# test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "# print(\"Соотношение объема обучающей/тестовой выборок: \"+str(X_train.shape[0])+'/'+str(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормировка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# # Create the scaler object with a range of 0-1\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# #scaler = StandardScaler()\n",
    "\n",
    "# # Fit on the training data\n",
    "# scaler.fit(X)\n",
    "\n",
    "# # Transform both the training and testing data\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# print(\"Проверка выборок:\")\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ корреляций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Карта корреляций "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = df.corr()\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "# plt.imshow(corr_matrix, cmap='coolwarm')\n",
    "# plt.colorbar()  # add color intensity map\n",
    "\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "# plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "# plt.yticks(range(len(corr_matrix)), corr_matrix.index)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Диаграмма корреляций прогнозируемой величины с величинами из набора векторов признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_4_analysis = pd.DataFrame().append(X)\n",
    "# data_4_analysis[pred_val] = y\n",
    "\n",
    "# # bar plot\n",
    "# pd.DataFrame(data_4_analysis.corr()[pred_val]).\\\n",
    "#              drop(index=[pred_val]).\\\n",
    "#              sort_values(by=[pred_val], ascending=False).\\\n",
    "#              plot(kind='bar')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ВНИАМАНИЕ!**\n",
    "\n",
    "В примере не приводится существенная оптимизация моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регрессионные модели МО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение используемой метрики (для всех регрессионных моделей):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring='r2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Метрики регрессии:*\n",
    "- `explained_variance`\n",
    "- `max_error`\n",
    "- `neg_mean_absolute_error`\n",
    "- `neg_mean_squared_error`\n",
    "- `neg_root_mean_squared_error`\n",
    "- `neg_mean_squared_log_error`\n",
    "- `neg_median_absolute_error`\n",
    "- `r2`\n",
    "- `neg_mean_poisson_deviance`\n",
    "- `neg_mean_gamma_deviance`\n",
    "- `neg_mean_absolute_percentage_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_table = pd.DataFrame()\n",
    "# tmp={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция построения графика $y_{pred}=f(y_{true})$ и отображения метрики $R^2$ в кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ex_plot(model_name, y_true, y_pred, scores):\n",
    "#     plt.plot(y_test, y_pred, 'o', label=str(scoring)+'(C-V) = '+str(round(scores,2)))\n",
    "    \n",
    "#     max_dimension = max(y_test.max(), y_pred.max())\n",
    "#     min_dimension = min(y_test.min(), y_pred.min())\n",
    "    \n",
    "#     x_line = [min_dimension, max_dimension]\n",
    "#     y_line = x_line\n",
    "    \n",
    "#     plt.plot(x_line, y_line)\n",
    "#     plt.xlabel('True value')\n",
    "#     plt.ylabel('Predicted value')\n",
    "#     plt.legend()\n",
    "#     plt.title(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение модели линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LinearRegression()\n",
    "\n",
    "# ''' MODEL FIT '''\n",
    "# lr.fit(X_train, y_train)\n",
    "   \n",
    "# ''' Cross-Validation '''\n",
    "# scores = cross_val_score(lr, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "# ''' PLOT '''\n",
    "# y_pred = lr.predict(X_test)\n",
    "# model_name='Linear Regression'\n",
    "# # ex_plot(model_name, y_test, y_pred, scores.mean())\n",
    "# # plt.show()\n",
    "\n",
    "# tmp['model'] = 'lr'\n",
    "# tmp[scoring] = scores.mean()\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загрузка библиотек\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Инициализация модели МО:\n",
    "# model_knr = KNeighborsRegressor()\n",
    "\n",
    "# # Массив числа соседей для перебора\n",
    "# n_neighbors = np.arange(1,11,1) # from 1 to 10\n",
    "\n",
    "# # Определение сетки параметров\n",
    "# param_grid = {'n_neighbors': n_neighbors}\n",
    "\n",
    "# # Инициирование поиска по сетке параметров\n",
    "# gs = GridSearchCV(model_knr, param_grid, cv = 5, verbose = 1, n_jobs=-1, scoring=scoring)\n",
    "# gs.fit(X_train, y_train)\n",
    "\n",
    "# # Определение наилучшей параметризации\n",
    "# model_best = gs.best_estimator_\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Таблица результатов поиска по сетке параметров\n",
    "# results = pd.DataFrame()\n",
    "# results['params'] = gs.cv_results_.get('params')\n",
    "# results['scores'] = gs.cv_results_.get('mean_test_score')\n",
    "# results['rank'] = gs.cv_results_.get('rank_test_score')\n",
    "# knn_res = results.sort_values(by='rank').set_index('rank')\n",
    "\n",
    "# tmp['model'] = 'knn'\n",
    "# tmp[scoring] = knn_res.head(1).scores.values[0]\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загрузка библиотек\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# # Инициализация модели МО:\n",
    "# svr = SVR()\n",
    "\n",
    "# # Массив параметров для перебора\n",
    "# kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# degree = [1]\n",
    "# tol = [0.0001, 0.001]\n",
    "# C = [0.6]\n",
    "# epsilon = [0.2]\n",
    "\n",
    "# param_grid = {'kernel': kernel, 'degree' : degree, 'tol' : tol, 'C' : C, 'epsilon' : epsilon}\n",
    "\n",
    "# gs = GridSearchCV(svr, param_grid, cv = 5, verbose = 1, n_jobs=-1, scoring=scoring)\n",
    "# gs.fit(X_train, y_train)\n",
    "# model_best = gs.best_estimator_\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Таблица результатов поиска по сетке параметров\n",
    "# results = pd.DataFrame()\n",
    "# results['params'] = gs.cv_results_.get('params')\n",
    "# results['scores'] = gs.cv_results_.get('mean_test_score')\n",
    "# results['rank'] = gs.cv_results_.get('rank_test_score')\n",
    "# svm_res = results.sort_values(by='rank').set_index('rank')\n",
    "\n",
    "# tmp['model'] = 'svm'\n",
    "# tmp[scoring] = svm_res.head(1).scores.values[0]\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# RFR = RandomForestRegressor()\n",
    "\n",
    "# n_estimators = [400, 500]\n",
    "# max_features = ['auto']\n",
    "# max_depth = [40]\n",
    "# min_samples_split = [0.001]\n",
    "# min_samples_leaf = [1]\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# param_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# gs = GridSearchCV(RFR, param_grid, cv = 5, verbose = 1, n_jobs=-1, scoring=scoring)\n",
    "# gs.fit(X_train, y_train)\n",
    "\n",
    "# model_best = gs.best_estimator_\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Таблица результатов поиска по сетке параметров\n",
    "# results = pd.DataFrame()\n",
    "# results['params'] = gs.cv_results_.get('params')\n",
    "# results['scores'] = gs.cv_results_.get('mean_test_score')\n",
    "# results['rank'] = gs.cv_results_.get('rank_test_score')\n",
    "# rfr_res = results.sort_values(by='rank').set_index('rank')\n",
    "\n",
    "# tmp['model'] = 'rfr'\n",
    "# tmp[scoring] = rfr_res.head(1).scores.values[0]\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# gbr = GradientBoostingRegressor()\n",
    "\n",
    "# # Массивы значений параметров для поиска по сетке\n",
    "# learning_rate = [0.001, 0.01, 0.1]\n",
    "# n_estimators = [300,350]\n",
    "# min_samples_split = [0.001,0.01, 0.1]\n",
    "# min_samples_leaf = [1,2]\n",
    "# max_depth = [1,5,15]\n",
    "\n",
    "# param_grid = { 'learning_rate': learning_rate,\n",
    "#                'n_estimators': n_estimators,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'max_depth': max_depth}\n",
    "\n",
    "# gs = GridSearchCV(gbr, param_grid, cv = 5, verbose = 1, n_jobs=-1, scoring=scoring)\n",
    "# gs.fit(X_train, y_train)\n",
    "# model_best = gs.best_estimator_\n",
    "# # print(\"------------------------------\")\n",
    "# # print(\"Параметры наилучшего варианта:\")\n",
    "# # print(gs.best_params_)\n",
    "# # print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Таблица результатов поиска по сетке параметров\n",
    "# results = pd.DataFrame()\n",
    "# results['params'] = gs.cv_results_.get('params')\n",
    "# results['scores'] = gs.cv_results_.get('mean_test_score')\n",
    "# results['rank'] = gs.cv_results_.get('rank_test_score')\n",
    "# gbr_res = results.sort_values(by='rank').set_index('rank').head(3)\n",
    "\n",
    "# tmp['model'] = 'gbr'\n",
    "# tmp[scoring] = gbr_res.head(1).scores.values[0]\n",
    "# res_table = res_table.append([tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(df.columns.values)\n",
    "# # res_table.r2.max()\n",
    "# res_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pre-requirements\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras import optimizers\n",
    "\n",
    "# # keras-tuner (general)\n",
    "# import tensorflow.keras as keras\n",
    "\n",
    "# # hyperparameter optimization algorithm\n",
    "# from kerastuner import Hyperband # OTHER MODULES: RandomSearch, BayesianOptimization\n",
    "\n",
    "# # easy calling\n",
    "# from kerastuner.engine.hypermodel import HyperModel\n",
    "# from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(hp):\n",
    "    \n",
    "#     ''' trial parameters '''\n",
    "#     # model type selection\n",
    "#     model = Sequential()\n",
    "        \n",
    "#     # model hyperparameters\n",
    "#     activation_choice = hp.Choice('activation', values=['relu', 'sigmoid'])\n",
    "#     optimizer_choice = hp.Choice('optimizer', values=['adam','rmsprop','SGD'])\n",
    "#     hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) \n",
    "    \n",
    "#     ''' ANN STRUCTURE '''\n",
    "#     # first h-layer\n",
    "#     model.add(Dense(units=hp.Int('layer_1', min_value=20, max_value=200, step=20),\n",
    "#                     input_dim=9,\n",
    "#                     activation=activation_choice))\n",
    "    \n",
    "#     # other h-layer \n",
    "#     # optimized for perfomance\n",
    "#     for i in range(hp.Int('num_layers', 2, 4)):\n",
    "#         model.add(Dense(units=hp.Int('layer_' + str(i), min_value=20, max_value=100, step=20),\n",
    "#                         activation=activation_choice))\n",
    "    \n",
    "#     # output layer\n",
    "#     model.add(Dense(1))\n",
    "    \n",
    "#     ''' instantiate ANN '''\n",
    "#     model.compile(optimizer=optimizer_choice,\n",
    "#                   loss='MSE',\n",
    "#                   metrics=['MSE'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = Hyperband(build_model,\n",
    "#                   objective='val_MSE',\n",
    "#                   max_epochs=500, # for Hyperband only\n",
    "#                   #max_trials=20, # for BayesianOptimization & RandomSearch\n",
    "#                   directory='test_dir') #, # ATTENTION! path should be latin!!!!!!\n",
    "#                   #overwrite=True) # overwrite all previous models in specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search(X_train, y_train, \n",
    "#              batch_size=200, # optimal batch size preselected\n",
    "#              # epochs=500,   # for BayesianOptimization & RandomSearch\n",
    "#              validation_split=0.2,\n",
    "#              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = tuner.get_best_models(num_models=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = models[0]\n",
    "# m2 = models[1]\n",
    "# m3 = models[2]\n",
    "# # m1.fit(X_train, y_train)\n",
    "# # m2.fit(X_train, y_train)\n",
    "# # m3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# def get_X_y(df_test, df_train):    \n",
    "#     X_train = df_train.copy().drop([pred_val], axis='columns')\n",
    "#     y_train = pd.DataFrame(df_train[pred_val])\n",
    "#     X_test = df_test.copy().drop([pred_val], axis='columns')\n",
    "#     y_test = pd.DataFrame(df_test[pred_val])\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     return X_train, y_train, X_test, y_test\n",
    "    \n",
    "# def get_predictions(model, X_train, y_train, X_test, y_test):\n",
    "#     model.fit(X_train, y_train, epochs=100, verbose=2)\n",
    "#     predicticted_values = model(X_test).numpy()\n",
    "#     predicticted_values = predicticted_values.reshape(predicticted_values.shape[0]) \n",
    "#     R2 = r2_score(y_test, predicticted_values) \n",
    "#     return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import IntProgress\n",
    "# from IPython.display import display\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# # splits number for k-fold C-V\n",
    "# n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "\n",
    "# # instantiate the bar\n",
    "# progress_bar = IntProgress(min=0, max=n_splits)\n",
    "# percentage = round(progress_bar.value*100/n_splits)\n",
    "# display(progress_bar) # display the bar\n",
    "\n",
    "# # temporary data for futher plotting\n",
    "# hist = pd.DataFrame()\n",
    "# tmp = {}\n",
    "\n",
    "# for train, test in kf.split(df):\n",
    "# #     new_model = m1\n",
    "#     new_model = keras.models.load_model('best_model.h5')\n",
    "#     df_train = df.iloc[train]\n",
    "#     df_test = df.iloc[test]\n",
    "#     X_train, y_train, X_test, y_test = get_X_y(df_test, df_train)\n",
    "#     R2 = get_predictions(new_model, X_train, y_train, X_test, y_test)\n",
    "#     tmp['Fold'] = progress_bar.value\n",
    "#     tmp['R2'] = R2\n",
    "#     hist = hist.append([tmp])\n",
    "    \n",
    "#     # progress bar update\n",
    "#     progress_bar.value += 1\n",
    "#     percentage = round(progress_bar.value*100/n_splits)\n",
    "#     progress_bar.description = str(percentage)+\" %\"\n",
    "\n",
    "# hist = hist.set_index(['Fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('best_model.h5')\n",
    "# model.fit(X_train, y_train, epochs=200)\n",
    "# predicticted_values = model(X_test).numpy()\n",
    "# predicticted_values = predicticted_values.reshape(predicticted_values.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(y_test, predicticted_values, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Восстановим в точности ту же модель, включая веса и оптимизатор\n",
    "# new_model = keras.models.load_model('best_model.h5')\n",
    "\n",
    "# # Покажем архитектуру модели\n",
    "# new_model.summary()\n",
    "\n",
    "# plot_model_fit(new_model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
